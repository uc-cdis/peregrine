# -*- coding: utf-8 -*-
"""
peregrine.resources.submission.constants
----------------------------------

Define variables to be imported to other modules.  These variables
contain things like state transition flows.

"""

import re
import uuid

# ======================================================================
# Dictionary Consts

#: Do we have a cache case setting and should we do it?
#: Do we have a cache case setting and should we do it?
def case_cache_enabled():
    """
    Return if the case cache is enabled or not. NOTE that the dictionary must be initialized
    first!

    .. note::

        This function assumes that the dictionary has already been initialized.
        The except/return None behavior is to, for example, allow Sphinx to
        still import/run individual modules without raising errors.
    """
    from peregrine import dictionary
    try:
        return (
            True if dictionary.settings == None
            else dictionary.settings.get('enable_case_cache', True)
        )
    except (AttributeError, KeyError, TypeError):
        return True


# ======================================================================
# File upload

#: State a file should be put in given an error
ERROR_STATE = 'error'

#: Initial file state
def submitted_state():
    """
    Return the initial file state. NOTE that the dictionary must be initialized
    first!

    This would be a global defined as:

    .. code-block:: python

        SUBMITTED_STATE = (
            dictionary.resolvers['_definitions.yaml'].source['file_state']['default']
        )

    but the dictionary must be initialized first, so this value cannot be used
    before that.

    .. note::

        This function assumes that the dictionary has already been initialized.
        The except/return None behavior is to, for example, allow Sphinx to
        still import/run individual modules without raising errors.
    """
    from peregrine import dictionary
    try:
        return (
            dictionary.resolvers['_definitions.yaml']
            .source['file_state']['default']
        )
    except (AttributeError, KeyError, TypeError):
        return None

#: State file enters when user begins upload
UPLOADING_STATE = 'uploading'

#: State file enters when user completes upload
SUCCESS_STATE = 'uploaded'

# ======================================================================
# Release/Submit workflow

#: UUID seeds for program/project uuid5 generation
uuid_regex = re.compile("^[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}$")
project_seed = uuid.UUID('249b4405-2c69-45d9-96bc-7410333d5d80')
program_seed = uuid.UUID('85b08c6a-56a6-4474-9c30-b65abfd214a8')


#: This is a list of states that an entity must be in to allow
#: deletion
ALLOWED_DELETION_STATES = [
    "validated",
]

#: This is a list of file_states that a a file must be in to allow
#: deletion
ALLOWED_DELETION_FILE_STATES = [
    submitted_state,
]


#: These categories should all have a ``state`` associated with each type
ENTITY_STATE_CATEGORIES = [
    'biospecimen',
    'clinical',
    'data_file',
    # 'cases' => cases are currently `admin` but are manually included
    #      in submission
    # 'annotations' => cases are currently `TBD` but are manually
    #      included in submission
]

#: Possible entity.state transitions
#: { to_state: from_state }
ENTITY_STATE_TRANSITIONS = {
    'submitted': ['validated', None],
}

#: The key that specifies the high level state that a file is in the
#: pipeline
FILE_STATE_KEY = 'file_state'

#: Possible data_file.file_state transitions
#: { to_state: from_state }
FILE_STATE_TRANSITIONS = {
    'submitted': ['validated'],
}

#: The auth role required to take action actions
ROLE_SUBMIT = 'release'
ROLE_REVIEW = 'release'
ROLE_OPEN = 'release'

#: The key that specifies the high level state that an entity is in the
#: release process
STATE_KEY = 'state'

#: Allow dry_run transactions to be committed (in a new transaction)
#: if the TransactionLog.state is in the following
STATES_COMITTABLE_DRY_RUN = {'SUCCEEDED'}

# ======================================================================
# Formats

FORMAT_JSON = 'JSON'
FORMAT_XML = 'XML'
FORMAT_TSV = 'TSV'
FORMAT_CSV = 'CSV'

# ======================================================================
# Transaction Logs

#: The transaction succeeded without user or system error.  If the
#: transaction was a non-dry_run mutation, then the result should be
#: represented in the database
TX_LOG_STATE_SUCCEEDED = 'SUCCEEDED'

#: The transaction failed due to user error
TX_LOG_STATE_FAILED = 'FAILED'

#: The transaction failed due to system error
TX_LOG_STATE_ERRORED = 'ERRORED'

#: The transaction is sill pending or a fatal event ended the job
#: before it could report an ERROR status
TX_LOG_STATE_PENDING = 'PENDING'

# ======================================================================
# Requests

#: Query param flag for performing transaction in background with
#: early return
FLAG_IS_ASYNC = 'async'
FLAG_IS_DRY_RUN = 'dry_run'

# ======================================================================
# Error messages

ERR_ASYNC_SCHEDULING = 'The API is currently under heavy load and currently has too many asynchronous tasks. Please try again later.'

#: Things go wrong, let's make a message for when they do
MESSAGE_500 = 'Internal server error. Sorry, something unexpected went wrong!'


# ======================================================================
# Async

ASYNC_MAX_Q_LEN = 128
